{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Importing Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,normalize"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reading train and test dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df_train = pd.read_csv('./Datasets/train.csv')\n",
    "df_test = pd.read_csv('./Datasets/test.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_test.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   EventId  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n",
       "0   245280      -999.000                       75.819        60.247     4.272   \n",
       "1   262684        48.837                       42.561        38.599    52.000   \n",
       "2   297196       109.825                        6.630        81.085    39.622   \n",
       "3   195128       132.732                       72.906       124.927     1.844   \n",
       "4   202281       105.644                       49.158        67.312    45.836   \n",
       "\n",
       "   DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0                -999.0            -999.0               -999.0   \n",
       "1                -999.0            -999.0               -999.0   \n",
       "2                -999.0            -999.0               -999.0   \n",
       "3                -999.0            -999.0               -999.0   \n",
       "4                -999.0            -999.0               -999.0   \n",
       "\n",
       "   DER_deltar_tau_lep  DER_pt_tot  ...  PRI_jet_num  PRI_jet_leading_pt  \\\n",
       "0               2.215       4.272  ...            0            -999.000   \n",
       "1               1.286       2.032  ...            1              50.286   \n",
       "2               3.192      39.622  ...            0            -999.000   \n",
       "3               3.397       1.844  ...            0            -999.000   \n",
       "4               2.586       5.066  ...            1              41.824   \n",
       "\n",
       "   PRI_jet_leading_eta  PRI_jet_leading_phi  PRI_jet_subleading_pt  \\\n",
       "0             -999.000             -999.000                 -999.0   \n",
       "1                1.964                0.240                 -999.0   \n",
       "2             -999.000             -999.000                 -999.0   \n",
       "3             -999.000             -999.000                 -999.0   \n",
       "4               -1.028                1.379                 -999.0   \n",
       "\n",
       "   PRI_jet_subleading_eta  PRI_jet_subleading_phi  PRI_jet_all_pt    Weight  \\\n",
       "0                  -999.0                  -999.0           0.000  4.683036   \n",
       "1                  -999.0                  -999.0          50.286  2.300551   \n",
       "2                  -999.0                  -999.0           0.000  0.018636   \n",
       "3                  -999.0                  -999.0           0.000  6.646627   \n",
       "4                  -999.0                  -999.0          41.824  1.454848   \n",
       "\n",
       "   Label  \n",
       "0      b  \n",
       "1      b  \n",
       "2      s  \n",
       "3      b  \n",
       "4      b  \n",
       "\n",
       "[5 rows x 33 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245280</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>75.819</td>\n",
       "      <td>60.247</td>\n",
       "      <td>4.272</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>2.215</td>\n",
       "      <td>4.272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.683036</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>262684</td>\n",
       "      <td>48.837</td>\n",
       "      <td>42.561</td>\n",
       "      <td>38.599</td>\n",
       "      <td>52.000</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.286</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>50.286</td>\n",
       "      <td>1.964</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>50.286</td>\n",
       "      <td>2.300551</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>297196</td>\n",
       "      <td>109.825</td>\n",
       "      <td>6.630</td>\n",
       "      <td>81.085</td>\n",
       "      <td>39.622</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>3.192</td>\n",
       "      <td>39.622</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.018636</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195128</td>\n",
       "      <td>132.732</td>\n",
       "      <td>72.906</td>\n",
       "      <td>124.927</td>\n",
       "      <td>1.844</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>3.397</td>\n",
       "      <td>1.844</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.646627</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202281</td>\n",
       "      <td>105.644</td>\n",
       "      <td>49.158</td>\n",
       "      <td>67.312</td>\n",
       "      <td>45.836</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>2.586</td>\n",
       "      <td>5.066</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-1.028</td>\n",
       "      <td>1.379</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>41.824</td>\n",
       "      <td>1.454848</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(\"Train dataset: \",df_train.shape)\n",
    "print(\"Test dataset: \",df_test.shape)\n",
    "\n",
    "#drop the weights column from train dataset\n",
    "df_train = df_train.drop(['Weight'],axis=1)\n",
    "df_test = df_test.drop(['Weight'],axis=1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train dataset:  (200000, 33)\n",
      "Test dataset:  (50000, 33)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysing Target column"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(df_train['Label'].value_counts())\n",
    "sns.barplot(x = df_train['Label'].value_counts().index, y = df_train['Label'].value_counts().values)\n",
    "plt.title('Label counts')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b    131456\n",
      "s     68544\n",
      "Name: Label, dtype: int64\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Label encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_train['Label'] = label_encoder.fit_transform(df_train.Label)\n",
    "df_train.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   EventId  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n",
       "0   211669       104.013                       30.973        72.342   107.323   \n",
       "1   145120        99.254                       40.244        72.411    22.628   \n",
       "2   275536       245.059                       33.030       200.144    26.154   \n",
       "3   292423       154.865                       41.603       106.340    65.308   \n",
       "4   119532        97.242                       62.288        73.844    32.605   \n",
       "\n",
       "   DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0                 6.674          1392.127              -11.131   \n",
       "1              -999.000          -999.000             -999.000   \n",
       "2              -999.000          -999.000             -999.000   \n",
       "3              -999.000          -999.000             -999.000   \n",
       "4              -999.000          -999.000             -999.000   \n",
       "\n",
       "   DER_deltar_tau_lep  DER_pt_tot  ...  PRI_met_sumet  PRI_jet_num  \\\n",
       "0               1.850      18.230  ...        279.175            2   \n",
       "1               3.216      22.628  ...         75.963            0   \n",
       "2               3.003      26.154  ...        208.793            0   \n",
       "3               2.963      34.115  ...        244.856            1   \n",
       "4               3.236      32.605  ...        118.445            0   \n",
       "\n",
       "   PRI_jet_leading_pt  PRI_jet_leading_eta  PRI_jet_leading_phi  \\\n",
       "0              51.011                3.397                1.594   \n",
       "1            -999.000             -999.000             -999.000   \n",
       "2            -999.000             -999.000             -999.000   \n",
       "3              84.492               -0.779                0.113   \n",
       "4            -999.000             -999.000             -999.000   \n",
       "\n",
       "   PRI_jet_subleading_pt  PRI_jet_subleading_eta  PRI_jet_subleading_phi  \\\n",
       "0                 48.108                  -3.276                   0.957   \n",
       "1               -999.000                -999.000                -999.000   \n",
       "2               -999.000                -999.000                -999.000   \n",
       "3               -999.000                -999.000                -999.000   \n",
       "4               -999.000                -999.000                -999.000   \n",
       "\n",
       "   PRI_jet_all_pt  Label  \n",
       "0          99.119      1  \n",
       "1           0.000      0  \n",
       "2           0.000      0  \n",
       "3          84.492      0  \n",
       "4          -0.000      1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211669</td>\n",
       "      <td>104.013</td>\n",
       "      <td>30.973</td>\n",
       "      <td>72.342</td>\n",
       "      <td>107.323</td>\n",
       "      <td>6.674</td>\n",
       "      <td>1392.127</td>\n",
       "      <td>-11.131</td>\n",
       "      <td>1.850</td>\n",
       "      <td>18.230</td>\n",
       "      <td>...</td>\n",
       "      <td>279.175</td>\n",
       "      <td>2</td>\n",
       "      <td>51.011</td>\n",
       "      <td>3.397</td>\n",
       "      <td>1.594</td>\n",
       "      <td>48.108</td>\n",
       "      <td>-3.276</td>\n",
       "      <td>0.957</td>\n",
       "      <td>99.119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>145120</td>\n",
       "      <td>99.254</td>\n",
       "      <td>40.244</td>\n",
       "      <td>72.411</td>\n",
       "      <td>22.628</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.216</td>\n",
       "      <td>22.628</td>\n",
       "      <td>...</td>\n",
       "      <td>75.963</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>275536</td>\n",
       "      <td>245.059</td>\n",
       "      <td>33.030</td>\n",
       "      <td>200.144</td>\n",
       "      <td>26.154</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.003</td>\n",
       "      <td>26.154</td>\n",
       "      <td>...</td>\n",
       "      <td>208.793</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>292423</td>\n",
       "      <td>154.865</td>\n",
       "      <td>41.603</td>\n",
       "      <td>106.340</td>\n",
       "      <td>65.308</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>2.963</td>\n",
       "      <td>34.115</td>\n",
       "      <td>...</td>\n",
       "      <td>244.856</td>\n",
       "      <td>1</td>\n",
       "      <td>84.492</td>\n",
       "      <td>-0.779</td>\n",
       "      <td>0.113</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>84.492</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119532</td>\n",
       "      <td>97.242</td>\n",
       "      <td>62.288</td>\n",
       "      <td>73.844</td>\n",
       "      <td>32.605</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.236</td>\n",
       "      <td>32.605</td>\n",
       "      <td>...</td>\n",
       "      <td>118.445</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "Y_train = df_train['Label']\n",
    "X_train = df_train.drop(['Label'],axis=1)\n",
    "Y_test = df_test['Label']\n",
    "X_test = df_test.drop(['Label'],axis=1)\n",
    "\n",
    "#setting index as eventid\n",
    "X_train.set_index(['EventId'],inplace = True)\n",
    "X_test.set_index(['EventId'],inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X_train = X_train.replace(-999.000,np.nan)\n",
    "X_test = X_test.replace(-999.000,np.nan)\n",
    "X_train.head()\n",
    "X_test.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n",
       "EventId                                                                      \n",
       "245280            NaN                       75.819        60.247     4.272   \n",
       "262684         48.837                       42.561        38.599    52.000   \n",
       "297196        109.825                        6.630        81.085    39.622   \n",
       "195128        132.732                       72.906       124.927     1.844   \n",
       "202281        105.644                       49.158        67.312    45.836   \n",
       "\n",
       "         DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "EventId                                                                \n",
       "245280                    NaN               NaN                  NaN   \n",
       "262684                    NaN               NaN                  NaN   \n",
       "297196                    NaN               NaN                  NaN   \n",
       "195128                    NaN               NaN                  NaN   \n",
       "202281                    NaN               NaN                  NaN   \n",
       "\n",
       "         DER_deltar_tau_lep  DER_pt_tot  DER_sum_pt  ...  PRI_met_phi  \\\n",
       "EventId                                              ...                \n",
       "245280                2.215       4.272      67.641  ...        2.965   \n",
       "262684                1.286       2.032     116.488  ...        1.516   \n",
       "297196                3.192      39.622      69.950  ...        2.910   \n",
       "195128                3.397       1.844      62.453  ...        2.235   \n",
       "202281                2.586       5.066     110.162  ...       -2.098   \n",
       "\n",
       "         PRI_met_sumet  PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  \\\n",
       "EventId                                                                        \n",
       "245280         111.755            0                 NaN                  NaN   \n",
       "262684         118.492            1              50.286                1.964   \n",
       "297196         201.376            0                 NaN                  NaN   \n",
       "195128         100.692            0                 NaN                  NaN   \n",
       "202281         226.477            1              41.824               -1.028   \n",
       "\n",
       "         PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "EventId                                                                       \n",
       "245280                   NaN                    NaN                     NaN   \n",
       "262684                 0.240                    NaN                     NaN   \n",
       "297196                   NaN                    NaN                     NaN   \n",
       "195128                   NaN                    NaN                     NaN   \n",
       "202281                 1.379                    NaN                     NaN   \n",
       "\n",
       "         PRI_jet_subleading_phi  PRI_jet_all_pt  \n",
       "EventId                                          \n",
       "245280                      NaN           0.000  \n",
       "262684                      NaN          50.286  \n",
       "297196                      NaN           0.000  \n",
       "195128                      NaN           0.000  \n",
       "202281                      NaN          41.824  \n",
       "\n",
       "[5 rows x 30 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EventId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245280</th>\n",
       "      <td>NaN</td>\n",
       "      <td>75.819</td>\n",
       "      <td>60.247</td>\n",
       "      <td>4.272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.215</td>\n",
       "      <td>4.272</td>\n",
       "      <td>67.641</td>\n",
       "      <td>...</td>\n",
       "      <td>2.965</td>\n",
       "      <td>111.755</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262684</th>\n",
       "      <td>48.837</td>\n",
       "      <td>42.561</td>\n",
       "      <td>38.599</td>\n",
       "      <td>52.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.286</td>\n",
       "      <td>2.032</td>\n",
       "      <td>116.488</td>\n",
       "      <td>...</td>\n",
       "      <td>1.516</td>\n",
       "      <td>118.492</td>\n",
       "      <td>1</td>\n",
       "      <td>50.286</td>\n",
       "      <td>1.964</td>\n",
       "      <td>0.240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297196</th>\n",
       "      <td>109.825</td>\n",
       "      <td>6.630</td>\n",
       "      <td>81.085</td>\n",
       "      <td>39.622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.192</td>\n",
       "      <td>39.622</td>\n",
       "      <td>69.950</td>\n",
       "      <td>...</td>\n",
       "      <td>2.910</td>\n",
       "      <td>201.376</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195128</th>\n",
       "      <td>132.732</td>\n",
       "      <td>72.906</td>\n",
       "      <td>124.927</td>\n",
       "      <td>1.844</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.397</td>\n",
       "      <td>1.844</td>\n",
       "      <td>62.453</td>\n",
       "      <td>...</td>\n",
       "      <td>2.235</td>\n",
       "      <td>100.692</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202281</th>\n",
       "      <td>105.644</td>\n",
       "      <td>49.158</td>\n",
       "      <td>67.312</td>\n",
       "      <td>45.836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.586</td>\n",
       "      <td>5.066</td>\n",
       "      <td>110.162</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.098</td>\n",
       "      <td>226.477</td>\n",
       "      <td>1</td>\n",
       "      <td>41.824</td>\n",
       "      <td>-1.028</td>\n",
       "      <td>1.379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "X_train.fillna(X_train.mean(), inplace=True)\n",
    "X_test.fillna(X_test.mean(), inplace=True)\n",
    "\n",
    "X_test.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  DER_pt_h  \\\n",
       "EventId                                                                      \n",
       "245280     121.427046                       75.819        60.247     4.272   \n",
       "262684      48.837000                       42.561        38.599    52.000   \n",
       "297196     109.825000                        6.630        81.085    39.622   \n",
       "195128     132.732000                       72.906       124.927     1.844   \n",
       "202281     105.644000                       49.158        67.312    45.836   \n",
       "\n",
       "         DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "EventId                                                                \n",
       "245280               2.395949        372.132373            -0.818362   \n",
       "262684               2.395949        372.132373            -0.818362   \n",
       "297196               2.395949        372.132373            -0.818362   \n",
       "195128               2.395949        372.132373            -0.818362   \n",
       "202281               2.395949        372.132373            -0.818362   \n",
       "\n",
       "         DER_deltar_tau_lep  DER_pt_tot  DER_sum_pt  ...  PRI_met_phi  \\\n",
       "EventId                                              ...                \n",
       "245280                2.215       4.272      67.641  ...        2.965   \n",
       "262684                1.286       2.032     116.488  ...        1.516   \n",
       "297196                3.192      39.622      69.950  ...        2.910   \n",
       "195128                3.397       1.844      62.453  ...        2.235   \n",
       "202281                2.586       5.066     110.162  ...       -2.098   \n",
       "\n",
       "         PRI_met_sumet  PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  \\\n",
       "EventId                                                                        \n",
       "245280         111.755            0           85.083091             0.003837   \n",
       "262684         118.492            1           50.286000             1.964000   \n",
       "297196         201.376            0           85.083091             0.003837   \n",
       "195128         100.692            0           85.083091             0.003837   \n",
       "202281         226.477            1           41.824000            -1.028000   \n",
       "\n",
       "         PRI_jet_leading_phi  PRI_jet_subleading_pt  PRI_jet_subleading_eta  \\\n",
       "EventId                                                                       \n",
       "245280             -0.013142              57.763971                0.004014   \n",
       "262684              0.240000              57.763971                0.004014   \n",
       "297196             -0.013142              57.763971                0.004014   \n",
       "195128             -0.013142              57.763971                0.004014   \n",
       "202281              1.379000              57.763971                0.004014   \n",
       "\n",
       "         PRI_jet_subleading_phi  PRI_jet_all_pt  \n",
       "EventId                                          \n",
       "245280                -0.000645           0.000  \n",
       "262684                -0.000645          50.286  \n",
       "297196                -0.000645           0.000  \n",
       "195128                -0.000645           0.000  \n",
       "202281                -0.000645          41.824  \n",
       "\n",
       "[5 rows x 30 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EventId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245280</th>\n",
       "      <td>121.427046</td>\n",
       "      <td>75.819</td>\n",
       "      <td>60.247</td>\n",
       "      <td>4.272</td>\n",
       "      <td>2.395949</td>\n",
       "      <td>372.132373</td>\n",
       "      <td>-0.818362</td>\n",
       "      <td>2.215</td>\n",
       "      <td>4.272</td>\n",
       "      <td>67.641</td>\n",
       "      <td>...</td>\n",
       "      <td>2.965</td>\n",
       "      <td>111.755</td>\n",
       "      <td>0</td>\n",
       "      <td>85.083091</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>-0.013142</td>\n",
       "      <td>57.763971</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262684</th>\n",
       "      <td>48.837000</td>\n",
       "      <td>42.561</td>\n",
       "      <td>38.599</td>\n",
       "      <td>52.000</td>\n",
       "      <td>2.395949</td>\n",
       "      <td>372.132373</td>\n",
       "      <td>-0.818362</td>\n",
       "      <td>1.286</td>\n",
       "      <td>2.032</td>\n",
       "      <td>116.488</td>\n",
       "      <td>...</td>\n",
       "      <td>1.516</td>\n",
       "      <td>118.492</td>\n",
       "      <td>1</td>\n",
       "      <td>50.286000</td>\n",
       "      <td>1.964000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>57.763971</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>50.286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297196</th>\n",
       "      <td>109.825000</td>\n",
       "      <td>6.630</td>\n",
       "      <td>81.085</td>\n",
       "      <td>39.622</td>\n",
       "      <td>2.395949</td>\n",
       "      <td>372.132373</td>\n",
       "      <td>-0.818362</td>\n",
       "      <td>3.192</td>\n",
       "      <td>39.622</td>\n",
       "      <td>69.950</td>\n",
       "      <td>...</td>\n",
       "      <td>2.910</td>\n",
       "      <td>201.376</td>\n",
       "      <td>0</td>\n",
       "      <td>85.083091</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>-0.013142</td>\n",
       "      <td>57.763971</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195128</th>\n",
       "      <td>132.732000</td>\n",
       "      <td>72.906</td>\n",
       "      <td>124.927</td>\n",
       "      <td>1.844</td>\n",
       "      <td>2.395949</td>\n",
       "      <td>372.132373</td>\n",
       "      <td>-0.818362</td>\n",
       "      <td>3.397</td>\n",
       "      <td>1.844</td>\n",
       "      <td>62.453</td>\n",
       "      <td>...</td>\n",
       "      <td>2.235</td>\n",
       "      <td>100.692</td>\n",
       "      <td>0</td>\n",
       "      <td>85.083091</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>-0.013142</td>\n",
       "      <td>57.763971</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202281</th>\n",
       "      <td>105.644000</td>\n",
       "      <td>49.158</td>\n",
       "      <td>67.312</td>\n",
       "      <td>45.836</td>\n",
       "      <td>2.395949</td>\n",
       "      <td>372.132373</td>\n",
       "      <td>-0.818362</td>\n",
       "      <td>2.586</td>\n",
       "      <td>5.066</td>\n",
       "      <td>110.162</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.098</td>\n",
       "      <td>226.477</td>\n",
       "      <td>1</td>\n",
       "      <td>41.824000</td>\n",
       "      <td>-1.028000</td>\n",
       "      <td>1.379000</td>\n",
       "      <td>57.763971</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>-0.000645</td>\n",
       "      <td>41.824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalizing the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#K Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=619, shuffle=True)\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", val_index)\n",
    "    xtrain, xvalid = X_train[train_index], X_train[val_index]\n",
    "\n",
    "    ytrain, yvalid = Y_train[train_index], Y_train[val_index]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN: [     0      2      3 ... 199996 199997 199998] TEST: [     1      5      9 ... 199986 199989 199999]\n",
      "TRAIN: [     0      1      4 ... 199994 199996 199999] TEST: [     2      3     10 ... 199995 199997 199998]\n",
      "TRAIN: [     0      1      2 ... 199997 199998 199999] TEST: [    21     24     26 ... 199987 199992 199994]\n",
      "TRAIN: [     1      2      3 ... 199997 199998 199999] TEST: [     0      6      7 ... 199978 199983 199996]\n",
      "TRAIN: [     0      1      2 ... 199997 199998 199999] TEST: [     4     22     23 ... 199985 199988 199990]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xvalid.shape)\n",
    "print(yvalid.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(160000, 30)\n",
      "(160000,)\n",
      "(40000, 30)\n",
      "(40000,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "#reshape for rnn\n",
    "\n",
    "X_train = xtrain.reshape(-1, 1, 30)\n",
    "X_val  = xvalid.reshape(-1, 1, 30)\n",
    "y_train = ytrain.values #convert pd to array\n",
    "y_train = y_train.reshape(-1, 1,)\n",
    "y_val = yvalid.values #convert pd to array\n",
    "y_val = y_val.reshape(-1, 1,)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "X_train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(160000, 1, 30)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from tensorflow.keras.layers import Conv2D,LSTM,LeakyReLU, MaxPooling2D,Concatenate,Input, Dropout, Flatten, Dense, GlobalAveragePooling2D,Activation, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "  # create model\n",
    "    \n",
    "\n",
    "#input \n",
    "input_layer = Input(shape=(1,30))\n",
    "main_rnn_layer = LSTM(64, return_sequences=True, recurrent_dropout=0.2)(input_layer)\n",
    "\n",
    "    \n",
    "#output\n",
    "rnn = LSTM(32)(main_rnn_layer)\n",
    "dense = Dense(128)(rnn)\n",
    "dropout_c = Dropout(0.3)(dense)\n",
    "Activation = LeakyReLU(alpha=0.1)(dropout_c)\n",
    "classes = Dense(1,name=\"class\")(Activation)\n",
    "\n",
    "model = Model(input_layer, classes)\n",
    "\n",
    "# Compile model\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', patience=4, verbose=1, factor=0.6),\n",
    "             EarlyStopping(monitor='val_loss', patience=20),\n",
    "             ModelCheckpoint(filepath='higgs.h5', monitor='val_loss', save_best_only=True)]\n",
    "model.compile(loss=[tf.keras.losses.MeanSquaredLogarithmicError(),tf.keras.losses.MeanSquaredLogarithmicError()], optimizer=\"adam\")\n",
    "\n",
    "\n",
    "model.summary()\n",
    "# Fit the model\n",
    "history = model.fit(X_train, y_train, \n",
    "          epochs = 250, \n",
    "          batch_size = 16, \n",
    "          validation_data=(X_val,  y_val), \n",
    "          callbacks=callbacks)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 1, 30)]           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 64)             24320     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "class (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 41,089\n",
      "Trainable params: 41,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/250\n",
      "10000/10000 [==============================] - 20s 2ms/step - loss: 0.0862 - val_loss: 0.0736\n",
      "Epoch 2/250\n",
      "10000/10000 [==============================] - 13s 1ms/step - loss: 0.0731 - val_loss: 0.0717\n",
      "Epoch 3/250\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.0706 - val_loss: 0.0702\n",
      "Epoch 4/250\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.0693 - val_loss: 0.0664\n",
      "Epoch 5/250\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.0670 - val_loss: 0.0664\n",
      "Epoch 6/250\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.0653 - val_loss: 0.0631\n",
      "Epoch 7/250\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.0641 - val_loss: 0.0620\n",
      "Epoch 8/250\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.0638 - val_loss: 0.0623\n",
      "Epoch 9/250\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.0631 - val_loss: 0.0612\n",
      "Epoch 10/250\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.0627 - val_loss: 0.0607\n",
      "Epoch 11/250\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.0620 - val_loss: 0.0618\n",
      "Epoch 12/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0614 - val_loss: 0.0615\n",
      "Epoch 13/250\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.0610 - val_loss: 0.0607\n",
      "Epoch 14/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0611 - val_loss: 0.0605\n",
      "Epoch 15/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0608 - val_loss: 0.0605\n",
      "Epoch 16/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0607 - val_loss: 0.0591\n",
      "Epoch 17/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0602 - val_loss: 0.0586\n",
      "Epoch 18/250\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.0603 - val_loss: 0.0586\n",
      "Epoch 19/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0597 - val_loss: 0.0606\n",
      "Epoch 20/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0589 - val_loss: 0.0584\n",
      "Epoch 21/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0596 - val_loss: 0.0580\n",
      "Epoch 22/250\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.0594 - val_loss: 0.0587\n",
      "Epoch 23/250\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.0592 - val_loss: 0.0581\n",
      "Epoch 24/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0589 - val_loss: 0.0578\n",
      "Epoch 25/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0587 - val_loss: 0.0585\n",
      "Epoch 26/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0589 - val_loss: 0.0592\n",
      "Epoch 27/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0587 - val_loss: 0.0583\n",
      "Epoch 28/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0585 - val_loss: 0.0710\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 29/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0578 - val_loss: 0.0573\n",
      "Epoch 30/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0573 - val_loss: 0.0580\n",
      "Epoch 31/250\n",
      "10000/10000 [==============================] - 14s 1ms/step - loss: 0.0573 - val_loss: 0.0586\n",
      "Epoch 32/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0574 - val_loss: 0.0583\n",
      "Epoch 33/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0570 - val_loss: 0.0573\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0003600000170990825.\n",
      "Epoch 34/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0569 - val_loss: 0.0578\n",
      "Epoch 35/250\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.0565 - val_loss: 0.0568\n",
      "Epoch 36/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0566 - val_loss: 0.0578\n",
      "Epoch 37/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0568 - val_loss: 0.0571\n",
      "Epoch 38/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0564 - val_loss: 0.0566\n",
      "Epoch 39/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0563 - val_loss: 0.0564\n",
      "Epoch 40/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0562 - val_loss: 0.0566\n",
      "Epoch 41/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0569 - val_loss: 0.0566\n",
      "Epoch 42/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0562 - val_loss: 0.0568\n",
      "Epoch 43/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0567 - val_loss: 0.0565\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00021600000327453016.\n",
      "Epoch 44/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0563 - val_loss: 0.0564\n",
      "Epoch 45/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0560 - val_loss: 0.0565\n",
      "Epoch 46/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0559 - val_loss: 0.0563\n",
      "Epoch 47/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0556 - val_loss: 0.0567\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.00012960000021848827.\n",
      "Epoch 48/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0559 - val_loss: 0.0561\n",
      "Epoch 49/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0555 - val_loss: 0.0563\n",
      "Epoch 50/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0555 - val_loss: 0.0562\n",
      "Epoch 51/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0560 - val_loss: 0.0565\n",
      "Epoch 52/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0554 - val_loss: 0.0563\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 7.775999838486313e-05.\n",
      "Epoch 53/250\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.0561 - val_loss: 0.0560\n",
      "Epoch 54/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0554 - val_loss: 0.0560\n",
      "Epoch 55/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0556 - val_loss: 0.0561\n",
      "Epoch 56/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0553 - val_loss: 0.0560\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 4.6655999904032795e-05.\n",
      "Epoch 57/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0553 - val_loss: 0.0559\n",
      "Epoch 58/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0558 - val_loss: 0.0560\n",
      "Epoch 59/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0551 - val_loss: 0.0560\n",
      "Epoch 60/250\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.0556 - val_loss: 0.0561\n",
      "Epoch 61/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0554 - val_loss: 0.0560\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 2.799360081553459e-05.\n",
      "Epoch 62/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0552 - val_loss: 0.0560\n",
      "Epoch 63/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0550 - val_loss: 0.0559\n",
      "Epoch 64/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0557 - val_loss: 0.0559\n",
      "Epoch 65/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0555 - val_loss: 0.0560\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 1.6796160707599483e-05.\n",
      "Epoch 66/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0553 - val_loss: 0.0559\n",
      "Epoch 67/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0550 - val_loss: 0.0559\n",
      "Epoch 68/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0554 - val_loss: 0.0559\n",
      "Epoch 69/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0552 - val_loss: 0.0559\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 1.007769642455969e-05.\n",
      "Epoch 70/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0551 - val_loss: 0.0559\n",
      "Epoch 71/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0550 - val_loss: 0.0559\n",
      "Epoch 72/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0553 - val_loss: 0.0559\n",
      "Epoch 73/250\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.0551 - val_loss: 0.0559\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 6.046617636457085e-06.\n",
      "Epoch 74/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0554 - val_loss: 0.0559\n",
      "Epoch 75/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0552 - val_loss: 0.0559\n",
      "Epoch 76/250\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.0549 - val_loss: 0.0559\n",
      "Epoch 77/250\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.0548 - val_loss: 0.0559\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 3.6279706364439334e-06.\n",
      "Epoch 78/250\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.0551 - val_loss: 0.0559\n",
      "Epoch 79/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0557 - val_loss: 0.0559\n",
      "Epoch 80/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0551 - val_loss: 0.0559\n",
      "Epoch 81/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0550 - val_loss: 0.0559\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 2.1767824364360423e-06.\n",
      "Epoch 82/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0550 - val_loss: 0.0559\n",
      "Epoch 83/250\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.0547 - val_loss: 0.0559\n",
      "Epoch 84/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0548 - val_loss: 0.0559\n",
      "Epoch 85/250\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.0554 - val_loss: 0.0559\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 1.3060694072919432e-06.\n",
      "Epoch 86/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0556 - val_loss: 0.0559\n",
      "Epoch 87/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0552 - val_loss: 0.0559\n",
      "Epoch 88/250\n",
      "10000/10000 [==============================] - 15s 1ms/step - loss: 0.0551 - val_loss: 0.0559\n",
      "Epoch 89/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0556 - val_loss: 0.0559\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 7.836416443751659e-07.\n",
      "Epoch 90/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0550 - val_loss: 0.0559\n",
      "Epoch 91/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0548 - val_loss: 0.0559\n",
      "Epoch 92/250\n",
      "10000/10000 [==============================] - 18s 2ms/step - loss: 0.0555 - val_loss: 0.0559\n",
      "Epoch 93/250\n",
      "10000/10000 [==============================] - 16s 2ms/step - loss: 0.0551 - val_loss: 0.0559\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 4.701850002675201e-07.\n",
      "Epoch 94/250\n",
      "10000/10000 [==============================] - 15s 2ms/step - loss: 0.0551 - val_loss: 0.0559\n",
      "Epoch 95/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0551 - val_loss: 0.0559\n",
      "Epoch 96/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0550 - val_loss: 0.0559\n",
      "Epoch 97/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0548 - val_loss: 0.0559\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 2.8211100016051206e-07.\n",
      "Epoch 98/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0550 - val_loss: 0.0559\n",
      "Epoch 99/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0551 - val_loss: 0.0559\n",
      "Epoch 100/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0551 - val_loss: 0.0559\n",
      "Epoch 101/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0550 - val_loss: 0.0559\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 1.6926659327509696e-07.\n",
      "Epoch 102/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0554 - val_loss: 0.0559\n",
      "Epoch 103/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0555 - val_loss: 0.0559\n",
      "Epoch 104/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0550 - val_loss: 0.0559\n",
      "Epoch 105/250\n",
      "10000/10000 [==============================] - 17s 2ms/step - loss: 0.0555 - val_loss: 0.0559\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 1.0155995937566331e-07.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss over epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='best')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "X_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(50000, 30)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "model.load_weights(\"higgs.h5\")\n",
    "\n",
    "test = X_test #convert pd to array\n",
    "test = test.reshape(-1, 1,30)\n",
    "\n",
    "\n",
    "predictions = model.predict(test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "print(predictions.shape)\n",
    "print(predictions)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(50000, 1)\n",
      "[[-0.00678288]\n",
      " [-0.06087816]\n",
      " [ 0.7602465 ]\n",
      " ...\n",
      " [ 0.6941203 ]\n",
      " [ 0.17027777]\n",
      " [ 0.18175305]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "pred = np.where(predictions > 0.5, 1, 0)\n",
    "pred"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "test_predict = pd.Series(pred[:,0])\n",
    "test_predict"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        1\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "49995    0\n",
       "49996    1\n",
       "49997    1\n",
       "49998    0\n",
       "49999    0\n",
       "Length: 50000, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "test_predict = test_predict.replace(1,'s')\n",
    "test_predict = test_predict.replace(0,'b')\n",
    "test_predict"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        b\n",
       "1        b\n",
       "2        s\n",
       "3        b\n",
       "4        b\n",
       "        ..\n",
       "49995    b\n",
       "49996    s\n",
       "49997    s\n",
       "49998    b\n",
       "49999    b\n",
       "Length: 50000, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "y_pred = test_predict.iloc[:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "y_pred"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        b\n",
       "1        b\n",
       "2        s\n",
       "3        b\n",
       "4        b\n",
       "        ..\n",
       "49995    b\n",
       "49996    s\n",
       "49997    s\n",
       "49998    b\n",
       "49999    b\n",
       "Length: 50000, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(Y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.83278\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit ('tensorflow': conda)"
  },
  "interpreter": {
   "hash": "d8b0e6390fd25117169903b2599cb669e8997234b61a2fce69567b58f380b070"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}